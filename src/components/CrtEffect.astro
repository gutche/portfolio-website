---
// Props for the component
const {
	isMobile = false,
	class: className,
	text = "",
	subText = "",
} = Astro.props;
---

<div
	class={`${isMobile ? "crt-container-mobile" : "crt-container"} ${className || ""}`}
	data-image-url={Astro.props.imageUrl}
	data-text={text}
	data-subtext={subText}>
</div>

<!-- Add Google Font -->
<link
	href="https://fonts.googleapis.com/css2?family=VT323&display=swap"
	rel="stylesheet"
/>
<script
	src="https://cdnjs.cloudflare.com/ajax/libs/fontfaceobserver/2.3.0/fontfaceobserver.js"
></script>

<script>
	import * as THREE from "three";

	declare class FontFaceObserver {
		constructor(family: string);
		load(): Promise<void>;
	}

	class CRTEffect {
		container: HTMLElement;
		width: number;
		height: number;
		scene: THREE.Scene = new THREE.Scene();
		camera: THREE.OrthographicCamera = new THREE.OrthographicCamera();
		renderer: THREE.WebGLRenderer = new THREE.WebGLRenderer();
		material: THREE.ShaderMaterial = new THREE.ShaderMaterial();

		constructor(container: HTMLElement) {
			this.container = container;
			this.width = Math.max(container.clientWidth, 1);
			this.height = Math.max(container.clientHeight, 1);
			
			this.setupScene();

			// Load the image before animation
			const imageUrl = container.getAttribute("data-image-url");
			if (imageUrl) {
				const loader = new THREE.TextureLoader();
				loader.load(imageUrl, (texture) => {
					// Set texture parameters for proper scaling
					texture.wrapS = THREE.ClampToEdgeWrapping;
					texture.wrapT = THREE.ClampToEdgeWrapping;
					texture.minFilter = THREE.LinearFilter;
					texture.magFilter = THREE.LinearFilter;

					this.material.uniforms.tDiffuse = { value: texture };

					// Create text texture if text is provided
					const text = container.getAttribute("data-text");
					const subText = container.getAttribute("data-subtext");
					if (text) {
						// Load font before creating text texture
						const font = new FontFaceObserver("VT323");
						font.load()
							.then(() => {
								const textTexture = this.createTextTexture(
									text,
									subText
								);
								this.material.uniforms.tText = {
									value: textTexture,
								};
							})
							.catch((error: Error) => {
								console.warn(
									"Font loading failed, falling back to monospace:",
									error
								);
								const textTexture = this.createTextTexture(
									text,
									subText
								);
								this.material.uniforms.tText = {
									value: textTexture,
								};
							});
					}
					this.animate();
				});
			} else {
				this.animate();
			}

			this.setupResizeListener();
		}

		createTextTexture(text: string, subText: string | null) {
			// Create a canvas for text
			const canvas = document.createElement("canvas");
			canvas.width = 512;
			canvas.height = 512;
			const ctx = canvas.getContext("2d");

			if (ctx) {
				// Clear with transparent background
				ctx.clearRect(0, 0, canvas.width, canvas.height);

				// Position text at bottom with padding
				const bottomPadding = 40;
				const leftPadding = 40;
				const boxWidth = canvas.width - leftPadding * 2;

				// Draw text box border with margin
				ctx.strokeStyle = "white";
				ctx.lineWidth = 1;
				ctx.beginPath();
				ctx.rect(
					leftPadding,
					canvas.height - bottomPadding - 80,
					boxWidth,
					70
				);
				ctx.stroke();

				// Draw main text with VT323 font
				ctx.fillStyle = "white";
				ctx.font = "28px VT323";
				ctx.fillText(
					text.toUpperCase(),
					leftPadding + 20,
					canvas.height - bottomPadding - 45
				);

				// Draw horizontal line below main text
				ctx.beginPath();
				ctx.moveTo(
					leftPadding + 10,
					canvas.height - bottomPadding - 40
				);
				ctx.lineTo(
					leftPadding + boxWidth - 10,
					canvas.height - bottomPadding - 40
				);
				ctx.stroke();

				// Draw subtext if provided with VT323 font
				if (subText) {
					ctx.font = "20px VT323";
					ctx.fillText(
						subText.toUpperCase(),
						leftPadding + 20,
						canvas.height - bottomPadding - 20
					);
				}
			}

			const texture = new THREE.CanvasTexture(canvas);
			texture.needsUpdate = true;
			return texture;
		}

		setupScene() {
			this.scene = new THREE.Scene();
			this.camera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0.1, 10);
			this.camera.position.z = 1;

			this.renderer = new THREE.WebGLRenderer({
				antialias: false,
				alpha: false,
				premultipliedAlpha: false,
			});
			this.renderer.setSize(this.width, this.height);
			this.renderer.setPixelRatio(window.devicePixelRatio);
			this.renderer.setClearColor(0x000000, 1);
			this.container.appendChild(this.renderer.domElement);

			const geometry = new THREE.PlaneGeometry(2, 2);

			// Create material
			this.material = new THREE.ShaderMaterial({
				uniforms: {
					tDiffuse: { value: null },
					tText: { value: null },
					time: { value: 0.0 },
					sIntensity: { value: 0.7 },
					sCount: { value: 1200 },
					nIntensity: { value: 0.2 },
					vIntensity: { value: 0.4 },
					brightness: { value: 1.1 },
					scanSpeed: { value: 0.25 },
					scanWidth: { value: 0.03 },
					pixelShift: { value: 0.025 }
				},
				vertexShader: `
					varying vec2 vUv;
					void main() {
						vUv = uv;
						gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
					}
				`,
				fragmentShader: `
					uniform sampler2D tDiffuse;
					uniform sampler2D tText;
					uniform float time;
					uniform float sIntensity;
					uniform float sCount;
					uniform float nIntensity;
					uniform float vIntensity;
					uniform float brightness;
					uniform float scanSpeed;
					uniform float scanWidth;
					uniform float pixelShift;
					varying vec2 vUv;

					float random(vec2 c) {
						return fract(sin(dot(c.xy, vec2(12.9898, 78.233))) * 43758.5453);
					}

					void main() {
						vec2 uv = vUv;
						
						// Scanning line distortion
						float scanPos = 1.0 - mod(time * scanSpeed, 1.0 + scanWidth * 2.0) + scanWidth;
						float scanEffect = smoothstep(scanPos - scanWidth, scanPos, uv.y) - 
										smoothstep(scanPos, scanPos + scanWidth, uv.y);
						
						// Apply horizontal shift at scan line
						vec2 distortedUv = uv;
						distortedUv.x += scanEffect * pixelShift;
						
						// Sample texture with distortion
						vec4 texel = texture2D(tDiffuse, distortedUv);
						
						// Create rolling scanlines
						float scanline = 0.5 + 0.5 * sin((uv.y + mod(time * 0.5, 1.0)) * sCount);
						scanline = 1.0 - (scanline * sIntensity);
						
						// Create static noise effect
						float noise = random(uv + vec2(time * 0.01)) * nIntensity;
						
						// Create rectangular vignette effect
						vec2 vignetteUv = abs(uv - 0.5) * 2.0;
						float vig = 1.0 - vIntensity * max(vignetteUv.x, vignetteUv.y);
						vig = pow(vig, 2.0);
						
						// Add chromatic aberration
						float aberration = 0.003;
						vec2 uvR = distortedUv + vec2(aberration, 0.0);
						vec2 uvB = distortedUv - vec2(aberration, 0.0);
						vec3 color;
						color.r = texture2D(tDiffuse, uvR).r;
						color.g = texel.g;
						color.b = texture2D(tDiffuse, uvB).b;
						
						// Composite the effects
						vec3 result = color;
						result *= scanline * vig * brightness;
						
						// Apply noise uniformly
						result += vec3(noise);
						
						// Get text with proper positioning - now using distorted UVs
						vec4 textColor = texture2D(tText, distortedUv);
						
						// Overlay text if present
						result = mix(result, textColor.rgb, textColor.a * 0.9);
						
						gl_FragColor = vec4(result, 1.0);
					}
				`,
				transparent: false
			});

			const plane = new THREE.Mesh(geometry, this.material);
			this.scene.add(plane);
			this.container.classList.add("loaded");
		}

		animate() {
			requestAnimationFrame(this.animate.bind(this));
			const time = performance.now() / 1000;
			this.material.uniforms.time.value = time;
			this.renderer.render(this.scene, this.camera);
		}

		setupResizeListener() {
			const debounce = (func: Function, wait: number) => {
				let timeout: number | null = null;
				return (...args: any[]) => {
					if (timeout !== null) {
						window.clearTimeout(timeout);
					}
					timeout = window.setTimeout(() => {
						func.apply(this, args);
						timeout = null;
					}, wait);
				};
			};

			const debouncedUpdate = debounce(() => {
				this.updateSize();
			}, 100);

			if (typeof ResizeObserver !== "undefined") {
				const resizeObserver = new ResizeObserver(() => {
					debouncedUpdate();
				});
				resizeObserver.observe(this.container);
			} else {
				window.addEventListener("resize", () => {
					debouncedUpdate();
				});
			}
		}

		updateSize() {
			this.width = Math.max(this.container.clientWidth, 1);
			this.height = Math.max(this.container.clientHeight, 1);
			this.renderer.setSize(this.width, this.height);
		}
	}

	document.addEventListener("DOMContentLoaded", () => {
		const containers = document.querySelectorAll(".crt-container, .crt-container-mobile");
		containers.forEach((container) => {
			if (!(container instanceof HTMLElement)) return;
			new CRTEffect(container);
		});
	});
</script>

<style>
	.crt-container,
	.crt-container-mobile {
		position: absolute;
		inset: 0;
		z-index: 5;
		overflow: hidden;
		display: flex;
		align-items: center;
		justify-content: center;
		width: 100%;
		height: 100%;
		border-radius: inherit;
	}

	.crt-container canvas,
	.crt-container-mobile canvas {
		width: 100%;
		height: 100%;
		display: block;
		object-fit: cover;
	}
</style>